{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
    "\n",
    "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "Device = cpu; Time per batch: 0.177 seconds\n",
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 3, 224, 224])\n",
      "Device = cuda; Time per batch: 0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        print(inputs.shape)\n",
    "        # Move input and label tensors to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
    "```python\n",
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 0.191..  Test Loss: 0.036..  Test Accuracy: 0.984\n",
      "Epoch: 2/2..  Training Loss: 0.182..  Test Loss: 0.034..  Test Accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "## Use a pretrained model to classify the cat and dog images\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.cuda()\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "test_losses, train_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "                \n",
    "#         images = images[:,1,:].view(images[:,1,:].shape[0],-1)\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in testloader:\n",
    "                \n",
    "#                 images = images[:,1,:].view(images[:,1,:].shape[0],-1)\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                \n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_ps, top_pred = ps.topk(1, dim=1)\n",
    "                \n",
    "                matches = top_pred == labels.view(*top_pred.shape)\n",
    "                accuracy += torch.mean(matches.type(torch.float))\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        test_losses.append(test_loss / len(testloader))\n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "        \n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "      \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "      \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resmodel = models.resnet50(pretrained=True)\n",
    "for params in resmodel.parameters():\n",
    "    params.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(nn.Linear(2048,128),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Dropout(p=0.2),\n",
    "                           nn.Linear(128,2),\n",
    "                           nn.LogSoftmax(dim=1))\n",
    "\n",
    "resmodel.fc = classifier\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(resmodel.fc.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "resmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validator(model, loader, batch_size):\n",
    "    \n",
    "    with torch.no_grad(): # turn off gradient calculations\n",
    "        model.eval() # turn off dropout\n",
    "        val_step = 0\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        for images, labels in loader: # images in validation set\n",
    "            val_step += 1\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device) # pushing to available device\n",
    "\n",
    "            log_ps = model.forward(images) # feed forward\n",
    "            ps = torch.exp(log_ps) # convert log to actual probabilities\n",
    "            top_ps, top_pred = ps.topk(1, dim=1) # get the top probability and its index\n",
    "\n",
    "            matches = top_pred == labels.view(*top_pred.shape) # compare prediction with actual labels\n",
    "            accuracy += torch.mean(matches.type(torch.float)) # compute and accumulate accuracy for this batch\n",
    "\n",
    "            batch_loss = criterion(log_ps, labels) # calculte loss in this run\n",
    "            val_loss += batch_loss.item() # accumulate validation losses\n",
    "\n",
    "            if val_step >= batch_size: # don't want to go through all the validations cases each time\n",
    "                break\n",
    "\n",
    "    model.train() # turn back on dropout\n",
    "    \n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 5..Train loss: 0.470.. Test loss: 0.872.. Test accuracy: 0.698\n",
      "Epoch 1/1.. Step 10..Train loss: 0.800.. Test loss: 0.248.. Test accuracy: 0.899\n",
      "Epoch 1/1.. Step 15..Train loss: 0.720.. Test loss: 0.178.. Test accuracy: 0.931\n",
      "Epoch 1/1.. Step 20..Train loss: 0.201.. Test loss: 0.134.. Test accuracy: 0.947\n",
      "Epoch 1/1.. Step 25..Train loss: 0.673.. Test loss: 0.090.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 30..Train loss: 0.568.. Test loss: 0.180.. Test accuracy: 0.924\n",
      "Epoch 1/1.. Step 35..Train loss: 0.420.. Test loss: 0.210.. Test accuracy: 0.919\n",
      "Epoch 1/1.. Step 40..Train loss: 0.625.. Test loss: 0.116.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 45..Train loss: 0.494.. Test loss: 0.198.. Test accuracy: 0.920\n",
      "Epoch 1/1.. Step 50..Train loss: 0.318.. Test loss: 0.153.. Test accuracy: 0.940\n",
      "Epoch 1/1.. Step 55..Train loss: 0.557.. Test loss: 0.126.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 60..Train loss: 0.236.. Test loss: 0.148.. Test accuracy: 0.956\n",
      "Epoch 1/1.. Step 65..Train loss: 0.246.. Test loss: 0.100.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 70..Train loss: 0.279.. Test loss: 0.175.. Test accuracy: 0.931\n",
      "Epoch 1/1.. Step 75..Train loss: 0.656.. Test loss: 0.117.. Test accuracy: 0.955\n",
      "Epoch 1/1.. Step 80..Train loss: 0.202.. Test loss: 0.183.. Test accuracy: 0.929\n",
      "Epoch 1/1.. Step 85..Train loss: 0.263.. Test loss: 0.129.. Test accuracy: 0.955\n",
      "Epoch 1/1.. Step 90..Train loss: 0.526.. Test loss: 0.168.. Test accuracy: 0.935\n",
      "Epoch 1/1.. Step 95..Train loss: 0.491.. Test loss: 0.111.. Test accuracy: 0.960\n",
      "Epoch 1/1.. Step 100..Train loss: 0.236.. Test loss: 0.106.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 105..Train loss: 0.277.. Test loss: 0.150.. Test accuracy: 0.943\n",
      "Epoch 1/1.. Step 110..Train loss: 0.672.. Test loss: 0.121.. Test accuracy: 0.957\n",
      "Epoch 1/1.. Step 115..Train loss: 0.631.. Test loss: 0.141.. Test accuracy: 0.955\n",
      "Epoch 1/1.. Step 120..Train loss: 0.310.. Test loss: 0.150.. Test accuracy: 0.954\n",
      "Epoch 1/1.. Step 125..Train loss: 0.455.. Test loss: 0.141.. Test accuracy: 0.959\n",
      "Epoch 1/1.. Step 130..Train loss: 0.456.. Test loss: 0.169.. Test accuracy: 0.940\n",
      "Epoch 1/1.. Step 135..Train loss: 0.427.. Test loss: 0.133.. Test accuracy: 0.958\n",
      "Epoch 1/1.. Step 140..Train loss: 0.173.. Test loss: 0.104.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 145..Train loss: 0.336.. Test loss: 0.099.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 150..Train loss: 0.327.. Test loss: 0.103.. Test accuracy: 0.966\n",
      "Epoch 1/1.. Step 155..Train loss: 0.290.. Test loss: 0.166.. Test accuracy: 0.937\n",
      "Epoch 1/1.. Step 160..Train loss: 0.387.. Test loss: 0.187.. Test accuracy: 0.929\n",
      "Epoch 1/1.. Step 165..Train loss: 0.170.. Test loss: 0.103.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 170..Train loss: 0.313.. Test loss: 0.091.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 175..Train loss: 0.184.. Test loss: 0.095.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 180..Train loss: 0.273.. Test loss: 0.086.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 185..Train loss: 0.130.. Test loss: 0.072.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 190..Train loss: 0.234.. Test loss: 0.068.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 195..Train loss: 0.096.. Test loss: 0.066.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 200..Train loss: 0.298.. Test loss: 0.067.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 205..Train loss: 0.171.. Test loss: 0.084.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 210..Train loss: 0.344.. Test loss: 0.070.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 215..Train loss: 0.337.. Test loss: 0.073.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 220..Train loss: 0.386.. Test loss: 0.166.. Test accuracy: 0.931\n",
      "Epoch 1/1.. Step 225..Train loss: 0.178.. Test loss: 0.173.. Test accuracy: 0.929\n",
      "Epoch 1/1.. Step 230..Train loss: 0.174.. Test loss: 0.158.. Test accuracy: 0.933\n",
      "Epoch 1/1.. Step 235..Train loss: 0.087.. Test loss: 0.088.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 240..Train loss: 0.370.. Test loss: 0.136.. Test accuracy: 0.947\n",
      "Epoch 1/1.. Step 245..Train loss: 0.531.. Test loss: 0.088.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 250..Train loss: 0.248.. Test loss: 0.116.. Test accuracy: 0.953\n",
      "Epoch 1/1.. Step 255..Train loss: 0.384.. Test loss: 0.074.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 260..Train loss: 0.229.. Test loss: 0.079.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 265..Train loss: 0.170.. Test loss: 0.072.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 270..Train loss: 0.294.. Test loss: 0.094.. Test accuracy: 0.964\n",
      "Epoch 1/1.. Step 275..Train loss: 0.486.. Test loss: 0.106.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 280..Train loss: 0.299.. Test loss: 0.088.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 285..Train loss: 0.375.. Test loss: 0.115.. Test accuracy: 0.965\n",
      "Epoch 1/1.. Step 290..Train loss: 0.391.. Test loss: 0.124.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 295..Train loss: 0.330.. Test loss: 0.105.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 300..Train loss: 0.247.. Test loss: 0.101.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 305..Train loss: 0.261.. Test loss: 0.103.. Test accuracy: 0.961\n",
      "Epoch 1/1.. Step 310..Train loss: 0.227.. Test loss: 0.074.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 315..Train loss: 0.307.. Test loss: 0.070.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 320..Train loss: 0.366.. Test loss: 0.145.. Test accuracy: 0.944\n",
      "Epoch 1/1.. Step 325..Train loss: 0.404.. Test loss: 0.078.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 330..Train loss: 0.419.. Test loss: 0.076.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 335..Train loss: 0.253.. Test loss: 0.095.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 340..Train loss: 0.271.. Test loss: 0.092.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 345..Train loss: 0.373.. Test loss: 0.075.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 350..Train loss: 0.187.. Test loss: 0.091.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 355..Train loss: 0.379.. Test loss: 0.065.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 360..Train loss: 0.330.. Test loss: 0.068.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 365..Train loss: 0.133.. Test loss: 0.060.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 370..Train loss: 0.140.. Test loss: 0.061.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 375..Train loss: 0.204.. Test loss: 0.057.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 380..Train loss: 0.235.. Test loss: 0.120.. Test accuracy: 0.954\n",
      "Epoch 1/1.. Step 385..Train loss: 0.327.. Test loss: 0.098.. Test accuracy: 0.961\n",
      "Epoch 1/1.. Step 390..Train loss: 0.230.. Test loss: 0.057.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 395..Train loss: 0.148.. Test loss: 0.144.. Test accuracy: 0.939\n",
      "Epoch 1/1.. Step 400..Train loss: 0.365.. Test loss: 0.060.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 405..Train loss: 0.250.. Test loss: 0.137.. Test accuracy: 0.948\n",
      "Epoch 1/1.. Step 410..Train loss: 0.436.. Test loss: 0.067.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 415..Train loss: 0.572.. Test loss: 0.088.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 420..Train loss: 0.264.. Test loss: 0.080.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 425..Train loss: 0.315.. Test loss: 0.099.. Test accuracy: 0.964\n",
      "Epoch 1/1.. Step 430..Train loss: 0.371.. Test loss: 0.084.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 435..Train loss: 0.325.. Test loss: 0.128.. Test accuracy: 0.949\n",
      "Epoch 1/1.. Step 440..Train loss: 0.229.. Test loss: 0.086.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 445..Train loss: 0.234.. Test loss: 0.070.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 450..Train loss: 0.276.. Test loss: 0.068.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 455..Train loss: 0.217.. Test loss: 0.065.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 460..Train loss: 0.222.. Test loss: 0.062.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 465..Train loss: 0.326.. Test loss: 0.068.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 470..Train loss: 0.415.. Test loss: 0.082.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 475..Train loss: 0.198.. Test loss: 0.075.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 480..Train loss: 0.189.. Test loss: 0.075.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 485..Train loss: 0.187.. Test loss: 0.075.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 490..Train loss: 0.558.. Test loss: 0.102.. Test accuracy: 0.958\n",
      "Epoch 1/1.. Step 495..Train loss: 0.375.. Test loss: 0.102.. Test accuracy: 0.960\n",
      "Epoch 1/1.. Step 500..Train loss: 0.353.. Test loss: 0.085.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 505..Train loss: 0.202.. Test loss: 0.108.. Test accuracy: 0.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 510..Train loss: 0.362.. Test loss: 0.058.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 515..Train loss: 0.274.. Test loss: 0.119.. Test accuracy: 0.952\n",
      "Epoch 1/1.. Step 520..Train loss: 0.181.. Test loss: 0.066.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 525..Train loss: 0.264.. Test loss: 0.054.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 530..Train loss: 0.260.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 535..Train loss: 0.239.. Test loss: 0.090.. Test accuracy: 0.965\n",
      "Epoch 1/1.. Step 540..Train loss: 0.304.. Test loss: 0.081.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 545..Train loss: 0.148.. Test loss: 0.061.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 550..Train loss: 0.352.. Test loss: 0.064.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 555..Train loss: 0.225.. Test loss: 0.063.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 560..Train loss: 0.293.. Test loss: 0.063.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 565..Train loss: 0.388.. Test loss: 0.162.. Test accuracy: 0.931\n",
      "Epoch 1/1.. Step 570..Train loss: 0.494.. Test loss: 0.105.. Test accuracy: 0.964\n",
      "Epoch 1/1.. Step 575..Train loss: 0.233.. Test loss: 0.082.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 580..Train loss: 0.201.. Test loss: 0.096.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 585..Train loss: 0.398.. Test loss: 0.084.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 590..Train loss: 0.270.. Test loss: 0.078.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 595..Train loss: 0.250.. Test loss: 0.070.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 600..Train loss: 0.268.. Test loss: 0.137.. Test accuracy: 0.940\n",
      "Epoch 1/1.. Step 605..Train loss: 0.789.. Test loss: 0.101.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 610..Train loss: 0.214.. Test loss: 0.087.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 615..Train loss: 0.192.. Test loss: 0.117.. Test accuracy: 0.954\n",
      "Epoch 1/1.. Step 620..Train loss: 0.332.. Test loss: 0.056.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 625..Train loss: 0.236.. Test loss: 0.052.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 630..Train loss: 0.192.. Test loss: 0.089.. Test accuracy: 0.966\n",
      "Epoch 1/1.. Step 635..Train loss: 0.114.. Test loss: 0.136.. Test accuracy: 0.951\n",
      "Epoch 1/1.. Step 640..Train loss: 0.523.. Test loss: 0.056.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 645..Train loss: 0.332.. Test loss: 0.157.. Test accuracy: 0.936\n",
      "Epoch 1/1.. Step 650..Train loss: 0.557.. Test loss: 0.061.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 655..Train loss: 0.274.. Test loss: 0.118.. Test accuracy: 0.954\n",
      "Epoch 1/1.. Step 660..Train loss: 0.417.. Test loss: 0.103.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 665..Train loss: 0.377.. Test loss: 0.089.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 670..Train loss: 0.344.. Test loss: 0.110.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 675..Train loss: 0.277.. Test loss: 0.086.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 680..Train loss: 0.262.. Test loss: 0.076.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 685..Train loss: 0.181.. Test loss: 0.088.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 690..Train loss: 0.159.. Test loss: 0.070.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 695..Train loss: 0.273.. Test loss: 0.063.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 700..Train loss: 0.169.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 705..Train loss: 0.228.. Test loss: 0.056.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 710..Train loss: 0.213.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 715..Train loss: 0.227.. Test loss: 0.053.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 720..Train loss: 0.488.. Test loss: 0.049.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 725..Train loss: 0.172.. Test loss: 0.079.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 730..Train loss: 0.119.. Test loss: 0.059.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 735..Train loss: 0.380.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 740..Train loss: 0.090.. Test loss: 0.054.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 745..Train loss: 0.099.. Test loss: 0.063.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 750..Train loss: 0.210.. Test loss: 0.079.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 755..Train loss: 0.264.. Test loss: 0.054.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 760..Train loss: 0.241.. Test loss: 0.052.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 765..Train loss: 0.509.. Test loss: 0.056.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 770..Train loss: 0.184.. Test loss: 0.064.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 775..Train loss: 0.390.. Test loss: 0.071.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 780..Train loss: 0.273.. Test loss: 0.088.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 785..Train loss: 0.619.. Test loss: 0.082.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 790..Train loss: 0.284.. Test loss: 0.074.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 795..Train loss: 0.284.. Test loss: 0.091.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 800..Train loss: 0.375.. Test loss: 0.079.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 805..Train loss: 0.230.. Test loss: 0.089.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 810..Train loss: 0.290.. Test loss: 0.074.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 815..Train loss: 0.365.. Test loss: 0.070.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 820..Train loss: 0.204.. Test loss: 0.103.. Test accuracy: 0.960\n",
      "Epoch 1/1.. Step 825..Train loss: 0.237.. Test loss: 0.092.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 830..Train loss: 0.136.. Test loss: 0.053.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 835..Train loss: 0.284.. Test loss: 0.051.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 840..Train loss: 0.161.. Test loss: 0.053.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 845..Train loss: 0.061.. Test loss: 0.056.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 850..Train loss: 0.403.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 855..Train loss: 0.237.. Test loss: 0.077.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 860..Train loss: 0.106.. Test loss: 0.066.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 865..Train loss: 0.335.. Test loss: 0.067.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 870..Train loss: 0.231.. Test loss: 0.068.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 875..Train loss: 0.455.. Test loss: 0.060.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 880..Train loss: 0.256.. Test loss: 0.117.. Test accuracy: 0.951\n",
      "Epoch 1/1.. Step 885..Train loss: 0.351.. Test loss: 0.069.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 890..Train loss: 0.250.. Test loss: 0.071.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 895..Train loss: 0.266.. Test loss: 0.061.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 900..Train loss: 0.225.. Test loss: 0.065.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 905..Train loss: 0.282.. Test loss: 0.073.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 910..Train loss: 0.543.. Test loss: 0.071.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 915..Train loss: 0.490.. Test loss: 0.069.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 920..Train loss: 0.321.. Test loss: 0.084.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 925..Train loss: 0.268.. Test loss: 0.103.. Test accuracy: 0.956\n",
      "Epoch 1/1.. Step 930..Train loss: 0.195.. Test loss: 0.062.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 935..Train loss: 0.146.. Test loss: 0.049.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 940..Train loss: 0.215.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 945..Train loss: 0.181.. Test loss: 0.047.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 950..Train loss: 0.118.. Test loss: 0.075.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 955..Train loss: 0.486.. Test loss: 0.049.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 960..Train loss: 0.220.. Test loss: 0.082.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 965..Train loss: 0.271.. Test loss: 0.060.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 970..Train loss: 0.266.. Test loss: 0.056.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 975..Train loss: 0.451.. Test loss: 0.088.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 980..Train loss: 0.364.. Test loss: 0.114.. Test accuracy: 0.957\n",
      "Epoch 1/1.. Step 985..Train loss: 0.314.. Test loss: 0.077.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 990..Train loss: 0.275.. Test loss: 0.071.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 995..Train loss: 0.281.. Test loss: 0.065.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1000..Train loss: 0.230.. Test loss: 0.062.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1005..Train loss: 0.630.. Test loss: 0.073.. Test accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 1010..Train loss: 0.271.. Test loss: 0.080.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1015..Train loss: 0.252.. Test loss: 0.073.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1020..Train loss: 0.331.. Test loss: 0.067.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1025..Train loss: 0.278.. Test loss: 0.064.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1030..Train loss: 0.460.. Test loss: 0.076.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 1035..Train loss: 0.251.. Test loss: 0.065.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1040..Train loss: 0.187.. Test loss: 0.066.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1045..Train loss: 0.211.. Test loss: 0.057.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1050..Train loss: 0.212.. Test loss: 0.061.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1055..Train loss: 0.300.. Test loss: 0.057.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1060..Train loss: 0.242.. Test loss: 0.055.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1065..Train loss: 0.408.. Test loss: 0.065.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1070..Train loss: 0.182.. Test loss: 0.065.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1075..Train loss: 0.179.. Test loss: 0.058.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1080..Train loss: 0.227.. Test loss: 0.054.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1085..Train loss: 0.353.. Test loss: 0.058.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1090..Train loss: 0.160.. Test loss: 0.119.. Test accuracy: 0.952\n",
      "Epoch 1/1.. Step 1095..Train loss: 0.211.. Test loss: 0.091.. Test accuracy: 0.961\n",
      "Epoch 1/1.. Step 1100..Train loss: 0.131.. Test loss: 0.059.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1105..Train loss: 0.164.. Test loss: 0.049.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1110..Train loss: 0.187.. Test loss: 0.058.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1115..Train loss: 0.407.. Test loss: 0.096.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 1120..Train loss: 0.227.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1125..Train loss: 0.228.. Test loss: 0.075.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 1130..Train loss: 0.569.. Test loss: 0.053.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1135..Train loss: 0.363.. Test loss: 0.075.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 1140..Train loss: 0.349.. Test loss: 0.063.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1145..Train loss: 0.146.. Test loss: 0.068.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1150..Train loss: 0.138.. Test loss: 0.062.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1155..Train loss: 0.189.. Test loss: 0.054.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1160..Train loss: 0.409.. Test loss: 0.077.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 1165..Train loss: 0.404.. Test loss: 0.101.. Test accuracy: 0.954\n",
      "Epoch 1/1.. Step 1170..Train loss: 0.296.. Test loss: 0.074.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 1175..Train loss: 0.425.. Test loss: 0.071.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1180..Train loss: 0.135.. Test loss: 0.076.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1185..Train loss: 0.237.. Test loss: 0.070.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1190..Train loss: 0.224.. Test loss: 0.059.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1195..Train loss: 0.224.. Test loss: 0.057.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1200..Train loss: 0.285.. Test loss: 0.051.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1205..Train loss: 0.133.. Test loss: 0.052.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1210..Train loss: 0.145.. Test loss: 0.067.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 1215..Train loss: 0.436.. Test loss: 0.083.. Test accuracy: 0.966\n",
      "Epoch 1/1.. Step 1220..Train loss: 0.133.. Test loss: 0.054.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1225..Train loss: 0.165.. Test loss: 0.058.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1230..Train loss: 0.224.. Test loss: 0.058.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1235..Train loss: 0.309.. Test loss: 0.061.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1240..Train loss: 0.229.. Test loss: 0.087.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 1245..Train loss: 0.366.. Test loss: 0.082.. Test accuracy: 0.965\n",
      "Epoch 1/1.. Step 1250..Train loss: 0.180.. Test loss: 0.063.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1255..Train loss: 0.354.. Test loss: 0.074.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 1260..Train loss: 0.171.. Test loss: 0.068.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1265..Train loss: 0.324.. Test loss: 0.069.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1270..Train loss: 0.271.. Test loss: 0.064.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1275..Train loss: 0.212.. Test loss: 0.067.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1280..Train loss: 0.315.. Test loss: 0.065.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1285..Train loss: 0.351.. Test loss: 0.067.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1290..Train loss: 0.356.. Test loss: 0.062.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1295..Train loss: 0.265.. Test loss: 0.064.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1300..Train loss: 0.308.. Test loss: 0.089.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 1305..Train loss: 0.336.. Test loss: 0.055.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1310..Train loss: 0.402.. Test loss: 0.062.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1315..Train loss: 0.165.. Test loss: 0.070.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1320..Train loss: 0.264.. Test loss: 0.069.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1325..Train loss: 0.221.. Test loss: 0.059.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1330..Train loss: 0.144.. Test loss: 0.057.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1335..Train loss: 0.373.. Test loss: 0.052.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1340..Train loss: 0.224.. Test loss: 0.047.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1345..Train loss: 0.371.. Test loss: 0.056.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1350..Train loss: 0.163.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1355..Train loss: 0.382.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1360..Train loss: 0.207.. Test loss: 0.057.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1365..Train loss: 0.263.. Test loss: 0.051.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1370..Train loss: 0.162.. Test loss: 0.054.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1375..Train loss: 0.275.. Test loss: 0.061.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1380..Train loss: 0.186.. Test loss: 0.064.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 1385..Train loss: 0.482.. Test loss: 0.064.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 1390..Train loss: 0.266.. Test loss: 0.064.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1395..Train loss: 0.270.. Test loss: 0.068.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1400..Train loss: 0.369.. Test loss: 0.077.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 1405..Train loss: 0.189.. Test loss: 0.087.. Test accuracy: 0.964\n",
      "Epoch 1/1.. Step 1410..Train loss: 0.370.. Test loss: 0.066.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1415..Train loss: 0.375.. Test loss: 0.070.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1420..Train loss: 0.365.. Test loss: 0.068.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1425..Train loss: 0.341.. Test loss: 0.078.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 1430..Train loss: 0.474.. Test loss: 0.067.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1435..Train loss: 0.441.. Test loss: 0.067.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1440..Train loss: 0.307.. Test loss: 0.071.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1445..Train loss: 0.253.. Test loss: 0.060.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1450..Train loss: 0.186.. Test loss: 0.069.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 1455..Train loss: 0.182.. Test loss: 0.071.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 1460..Train loss: 0.179.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1465..Train loss: 0.330.. Test loss: 0.054.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1470..Train loss: 0.306.. Test loss: 0.075.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 1475..Train loss: 0.214.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1480..Train loss: 0.275.. Test loss: 0.056.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1485..Train loss: 0.265.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1490..Train loss: 0.159.. Test loss: 0.054.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1495..Train loss: 0.231.. Test loss: 0.060.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1500..Train loss: 0.345.. Test loss: 0.072.. Test accuracy: 0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 1505..Train loss: 0.179.. Test loss: 0.059.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1510..Train loss: 0.269.. Test loss: 0.050.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1515..Train loss: 0.263.. Test loss: 0.050.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1520..Train loss: 0.105.. Test loss: 0.060.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 1525..Train loss: 0.262.. Test loss: 0.083.. Test accuracy: 0.967\n",
      "Epoch 1/1.. Step 1530..Train loss: 0.378.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1535..Train loss: 0.230.. Test loss: 0.062.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1540..Train loss: 0.130.. Test loss: 0.067.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1545..Train loss: 0.176.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1550..Train loss: 0.262.. Test loss: 0.046.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1555..Train loss: 0.169.. Test loss: 0.057.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1560..Train loss: 0.545.. Test loss: 0.057.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1565..Train loss: 0.145.. Test loss: 0.079.. Test accuracy: 0.966\n",
      "Epoch 1/1.. Step 1570..Train loss: 0.246.. Test loss: 0.060.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1575..Train loss: 0.288.. Test loss: 0.048.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1580..Train loss: 0.300.. Test loss: 0.050.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1585..Train loss: 0.262.. Test loss: 0.061.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1590..Train loss: 0.193.. Test loss: 0.052.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1595..Train loss: 0.112.. Test loss: 0.071.. Test accuracy: 0.970\n",
      "Epoch 1/1.. Step 1600..Train loss: 0.268.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1605..Train loss: 0.208.. Test loss: 0.054.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1610..Train loss: 0.142.. Test loss: 0.093.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 1615..Train loss: 0.222.. Test loss: 0.061.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1620..Train loss: 0.213.. Test loss: 0.056.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1625..Train loss: 0.302.. Test loss: 0.044.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1630..Train loss: 0.291.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1635..Train loss: 0.735.. Test loss: 0.054.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 1640..Train loss: 0.482.. Test loss: 0.090.. Test accuracy: 0.966\n",
      "Epoch 1/1.. Step 1645..Train loss: 0.338.. Test loss: 0.121.. Test accuracy: 0.960\n",
      "Epoch 1/1.. Step 1650..Train loss: 0.292.. Test loss: 0.101.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 1655..Train loss: 0.252.. Test loss: 0.065.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1660..Train loss: 0.224.. Test loss: 0.059.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1665..Train loss: 0.207.. Test loss: 0.049.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1670..Train loss: 0.230.. Test loss: 0.044.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1675..Train loss: 0.381.. Test loss: 0.057.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1680..Train loss: 0.491.. Test loss: 0.096.. Test accuracy: 0.960\n",
      "Epoch 1/1.. Step 1685..Train loss: 0.559.. Test loss: 0.081.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 1690..Train loss: 0.384.. Test loss: 0.077.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1695..Train loss: 0.227.. Test loss: 0.068.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1700..Train loss: 0.156.. Test loss: 0.057.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1705..Train loss: 0.214.. Test loss: 0.053.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1710..Train loss: 0.199.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1715..Train loss: 0.173.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1720..Train loss: 0.106.. Test loss: 0.059.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1725..Train loss: 0.151.. Test loss: 0.065.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1730..Train loss: 0.198.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1735..Train loss: 0.221.. Test loss: 0.046.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1740..Train loss: 0.163.. Test loss: 0.058.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1745..Train loss: 0.374.. Test loss: 0.052.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1750..Train loss: 0.266.. Test loss: 0.064.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 1755..Train loss: 0.439.. Test loss: 0.066.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1760..Train loss: 0.205.. Test loss: 0.060.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 1765..Train loss: 0.187.. Test loss: 0.074.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 1770..Train loss: 0.202.. Test loss: 0.080.. Test accuracy: 0.965\n",
      "Epoch 1/1.. Step 1775..Train loss: 0.258.. Test loss: 0.048.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1780..Train loss: 0.397.. Test loss: 0.046.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1785..Train loss: 0.408.. Test loss: 0.078.. Test accuracy: 0.968\n",
      "Epoch 1/1.. Step 1790..Train loss: 0.484.. Test loss: 0.059.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1795..Train loss: 0.158.. Test loss: 0.062.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 1800..Train loss: 0.314.. Test loss: 0.063.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 1805..Train loss: 0.344.. Test loss: 0.056.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 1810..Train loss: 0.116.. Test loss: 0.063.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1815..Train loss: 0.268.. Test loss: 0.066.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1820..Train loss: 0.274.. Test loss: 0.055.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1825..Train loss: 0.263.. Test loss: 0.050.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1830..Train loss: 0.248.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1835..Train loss: 0.333.. Test loss: 0.055.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1840..Train loss: 0.188.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1845..Train loss: 0.218.. Test loss: 0.048.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1850..Train loss: 0.303.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1855..Train loss: 0.196.. Test loss: 0.047.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1860..Train loss: 0.171.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1865..Train loss: 0.254.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1870..Train loss: 0.273.. Test loss: 0.060.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1875..Train loss: 0.268.. Test loss: 0.119.. Test accuracy: 0.956\n",
      "Epoch 1/1.. Step 1880..Train loss: 0.414.. Test loss: 0.077.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 1885..Train loss: 0.229.. Test loss: 0.065.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1890..Train loss: 0.263.. Test loss: 0.070.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1895..Train loss: 0.230.. Test loss: 0.061.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1900..Train loss: 0.454.. Test loss: 0.061.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1905..Train loss: 0.288.. Test loss: 0.064.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1910..Train loss: 0.187.. Test loss: 0.074.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 1915..Train loss: 0.240.. Test loss: 0.066.. Test accuracy: 0.974\n",
      "Epoch 1/1.. Step 1920..Train loss: 0.380.. Test loss: 0.056.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1925..Train loss: 0.192.. Test loss: 0.051.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1930..Train loss: 0.179.. Test loss: 0.048.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1935..Train loss: 0.098.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 1940..Train loss: 0.613.. Test loss: 0.048.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 1945..Train loss: 0.207.. Test loss: 0.088.. Test accuracy: 0.962\n",
      "Epoch 1/1.. Step 1950..Train loss: 0.307.. Test loss: 0.091.. Test accuracy: 0.958\n",
      "Epoch 1/1.. Step 1955..Train loss: 0.587.. Test loss: 0.063.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 1960..Train loss: 0.225.. Test loss: 0.103.. Test accuracy: 0.956\n",
      "Epoch 1/1.. Step 1965..Train loss: 0.398.. Test loss: 0.081.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 1970..Train loss: 0.243.. Test loss: 0.063.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1975..Train loss: 0.139.. Test loss: 0.061.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1980..Train loss: 0.220.. Test loss: 0.049.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 1985..Train loss: 0.233.. Test loss: 0.046.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 1990..Train loss: 0.301.. Test loss: 0.091.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 1995..Train loss: 0.297.. Test loss: 0.098.. Test accuracy: 0.960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 2000..Train loss: 0.310.. Test loss: 0.047.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2005..Train loss: 0.353.. Test loss: 0.048.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2010..Train loss: 0.109.. Test loss: 0.050.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2015..Train loss: 0.424.. Test loss: 0.047.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2020..Train loss: 0.339.. Test loss: 0.057.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2025..Train loss: 0.147.. Test loss: 0.053.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2030..Train loss: 0.333.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2035..Train loss: 0.354.. Test loss: 0.057.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2040..Train loss: 0.213.. Test loss: 0.068.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2045..Train loss: 0.303.. Test loss: 0.064.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2050..Train loss: 0.403.. Test loss: 0.066.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2055..Train loss: 0.302.. Test loss: 0.075.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 2060..Train loss: 0.321.. Test loss: 0.068.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2065..Train loss: 0.358.. Test loss: 0.058.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2070..Train loss: 0.242.. Test loss: 0.057.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2075..Train loss: 0.265.. Test loss: 0.055.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2080..Train loss: 0.129.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2085..Train loss: 0.303.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2090..Train loss: 0.248.. Test loss: 0.086.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 2095..Train loss: 0.125.. Test loss: 0.051.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2100..Train loss: 0.090.. Test loss: 0.051.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2105..Train loss: 0.347.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2110..Train loss: 0.202.. Test loss: 0.056.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2115..Train loss: 0.276.. Test loss: 0.048.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2120..Train loss: 0.215.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2125..Train loss: 0.233.. Test loss: 0.050.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2130..Train loss: 0.341.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2135..Train loss: 0.123.. Test loss: 0.056.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2140..Train loss: 0.275.. Test loss: 0.068.. Test accuracy: 0.971\n",
      "Epoch 1/1.. Step 2145..Train loss: 0.295.. Test loss: 0.074.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 2150..Train loss: 0.233.. Test loss: 0.056.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2155..Train loss: 0.222.. Test loss: 0.061.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 2160..Train loss: 0.407.. Test loss: 0.067.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 2165..Train loss: 0.313.. Test loss: 0.065.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 2170..Train loss: 0.186.. Test loss: 0.100.. Test accuracy: 0.961\n",
      "Epoch 1/1.. Step 2175..Train loss: 0.327.. Test loss: 0.077.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 2180..Train loss: 0.218.. Test loss: 0.055.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2185..Train loss: 0.180.. Test loss: 0.052.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2190..Train loss: 0.299.. Test loss: 0.053.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 2195..Train loss: 0.169.. Test loss: 0.054.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2200..Train loss: 0.102.. Test loss: 0.048.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2205..Train loss: 0.706.. Test loss: 0.058.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 2210..Train loss: 0.279.. Test loss: 0.068.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 2215..Train loss: 0.285.. Test loss: 0.065.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2220..Train loss: 0.254.. Test loss: 0.064.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2225..Train loss: 0.302.. Test loss: 0.111.. Test accuracy: 0.949\n",
      "Epoch 1/1.. Step 2230..Train loss: 0.205.. Test loss: 0.069.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 2235..Train loss: 0.516.. Test loss: 0.055.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2240..Train loss: 0.214.. Test loss: 0.048.. Test accuracy: 0.986\n",
      "Epoch 1/1.. Step 2245..Train loss: 0.348.. Test loss: 0.049.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2250..Train loss: 0.129.. Test loss: 0.054.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2255..Train loss: 0.159.. Test loss: 0.046.. Test accuracy: 0.986\n",
      "Epoch 1/1.. Step 2260..Train loss: 0.254.. Test loss: 0.045.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 2265..Train loss: 0.349.. Test loss: 0.044.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2270..Train loss: 0.208.. Test loss: 0.047.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2275..Train loss: 0.185.. Test loss: 0.047.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2280..Train loss: 0.188.. Test loss: 0.047.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2285..Train loss: 0.135.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2290..Train loss: 0.197.. Test loss: 0.047.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2295..Train loss: 0.459.. Test loss: 0.055.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2300..Train loss: 0.247.. Test loss: 0.058.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2305..Train loss: 0.216.. Test loss: 0.058.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2310..Train loss: 0.284.. Test loss: 0.060.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2315..Train loss: 0.303.. Test loss: 0.050.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2320..Train loss: 0.435.. Test loss: 0.060.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 2325..Train loss: 0.360.. Test loss: 0.058.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2330..Train loss: 0.326.. Test loss: 0.069.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2335..Train loss: 0.292.. Test loss: 0.066.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2340..Train loss: 0.206.. Test loss: 0.060.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2345..Train loss: 0.150.. Test loss: 0.060.. Test accuracy: 0.975\n",
      "Epoch 1/1.. Step 2350..Train loss: 0.348.. Test loss: 0.065.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 2355..Train loss: 0.244.. Test loss: 0.046.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2360..Train loss: 0.298.. Test loss: 0.046.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2365..Train loss: 0.167.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 1/1.. Step 2370..Train loss: 0.114.. Test loss: 0.043.. Test accuracy: 0.986\n",
      "Epoch 1/1.. Step 2375..Train loss: 0.326.. Test loss: 0.052.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2380..Train loss: 0.237.. Test loss: 0.043.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2385..Train loss: 0.113.. Test loss: 0.044.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2390..Train loss: 0.377.. Test loss: 0.041.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 2395..Train loss: 0.150.. Test loss: 0.044.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2400..Train loss: 0.345.. Test loss: 0.072.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 2405..Train loss: 0.504.. Test loss: 0.070.. Test accuracy: 0.973\n",
      "Epoch 1/1.. Step 2410..Train loss: 0.464.. Test loss: 0.068.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2415..Train loss: 0.256.. Test loss: 0.083.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2420..Train loss: 0.256.. Test loss: 0.084.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2425..Train loss: 0.195.. Test loss: 0.056.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2430..Train loss: 0.456.. Test loss: 0.057.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2435..Train loss: 0.549.. Test loss: 0.069.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2440..Train loss: 0.237.. Test loss: 0.077.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2445..Train loss: 0.340.. Test loss: 0.078.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2450..Train loss: 0.208.. Test loss: 0.060.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2455..Train loss: 0.406.. Test loss: 0.051.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2460..Train loss: 0.229.. Test loss: 0.050.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2465..Train loss: 0.316.. Test loss: 0.059.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 2470..Train loss: 0.196.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2475..Train loss: 0.221.. Test loss: 0.065.. Test accuracy: 0.976\n",
      "Epoch 1/1.. Step 2480..Train loss: 0.554.. Test loss: 0.058.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2485..Train loss: 0.323.. Test loss: 0.068.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2490..Train loss: 0.239.. Test loss: 0.081.. Test accuracy: 0.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Step 2495..Train loss: 0.299.. Test loss: 0.072.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2500..Train loss: 0.343.. Test loss: 0.061.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2505..Train loss: 0.248.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2510..Train loss: 0.346.. Test loss: 0.049.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2515..Train loss: 0.196.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2520..Train loss: 0.146.. Test loss: 0.041.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2525..Train loss: 0.299.. Test loss: 0.044.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2530..Train loss: 0.305.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2535..Train loss: 0.123.. Test loss: 0.047.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2540..Train loss: 0.223.. Test loss: 0.056.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2545..Train loss: 0.557.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2550..Train loss: 0.257.. Test loss: 0.091.. Test accuracy: 0.959\n",
      "Epoch 1/1.. Step 2555..Train loss: 0.357.. Test loss: 0.083.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 2560..Train loss: 0.196.. Test loss: 0.060.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2565..Train loss: 0.429.. Test loss: 0.063.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 2570..Train loss: 0.137.. Test loss: 0.060.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 2575..Train loss: 0.277.. Test loss: 0.048.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2580..Train loss: 0.215.. Test loss: 0.051.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2585..Train loss: 0.514.. Test loss: 0.055.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2590..Train loss: 0.565.. Test loss: 0.073.. Test accuracy: 0.986\n",
      "Epoch 1/1.. Step 2595..Train loss: 0.396.. Test loss: 0.101.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2600..Train loss: 0.377.. Test loss: 0.108.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 2605..Train loss: 0.437.. Test loss: 0.109.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2610..Train loss: 0.283.. Test loss: 0.092.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2615..Train loss: 0.246.. Test loss: 0.059.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2620..Train loss: 0.241.. Test loss: 0.051.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2625..Train loss: 0.294.. Test loss: 0.051.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2630..Train loss: 0.264.. Test loss: 0.041.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 2635..Train loss: 0.214.. Test loss: 0.046.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2640..Train loss: 0.250.. Test loss: 0.044.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 2645..Train loss: 0.348.. Test loss: 0.046.. Test accuracy: 0.985\n",
      "Epoch 1/1.. Step 2650..Train loss: 0.216.. Test loss: 0.050.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2655..Train loss: 0.344.. Test loss: 0.058.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2660..Train loss: 0.364.. Test loss: 0.068.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2665..Train loss: 0.284.. Test loss: 0.068.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2670..Train loss: 0.271.. Test loss: 0.068.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2675..Train loss: 0.213.. Test loss: 0.060.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2680..Train loss: 0.242.. Test loss: 0.054.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2685..Train loss: 0.342.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2690..Train loss: 0.205.. Test loss: 0.050.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2695..Train loss: 0.212.. Test loss: 0.056.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2700..Train loss: 0.158.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2705..Train loss: 0.188.. Test loss: 0.044.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2710..Train loss: 0.359.. Test loss: 0.056.. Test accuracy: 0.979\n",
      "Epoch 1/1.. Step 2715..Train loss: 0.328.. Test loss: 0.085.. Test accuracy: 0.965\n",
      "Epoch 1/1.. Step 2720..Train loss: 0.443.. Test loss: 0.057.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2725..Train loss: 0.235.. Test loss: 0.083.. Test accuracy: 0.963\n",
      "Epoch 1/1.. Step 2730..Train loss: 0.223.. Test loss: 0.089.. Test accuracy: 0.961\n",
      "Epoch 1/1.. Step 2735..Train loss: 0.264.. Test loss: 0.078.. Test accuracy: 0.969\n",
      "Epoch 1/1.. Step 2740..Train loss: 0.258.. Test loss: 0.055.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2745..Train loss: 0.267.. Test loss: 0.047.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2750..Train loss: 0.125.. Test loss: 0.042.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2755..Train loss: 0.190.. Test loss: 0.045.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2760..Train loss: 0.253.. Test loss: 0.046.. Test accuracy: 0.981\n",
      "Epoch 1/1.. Step 2765..Train loss: 0.214.. Test loss: 0.065.. Test accuracy: 0.972\n",
      "Epoch 1/1.. Step 2770..Train loss: 0.348.. Test loss: 0.049.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2775..Train loss: 0.176.. Test loss: 0.043.. Test accuracy: 0.983\n",
      "Epoch 1/1.. Step 2780..Train loss: 0.148.. Test loss: 0.059.. Test accuracy: 0.977\n",
      "Epoch 1/1.. Step 2785..Train loss: 0.335.. Test loss: 0.049.. Test accuracy: 0.984\n",
      "Epoch 1/1.. Step 2790..Train loss: 0.200.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "Epoch 1/1.. Step 2795..Train loss: 0.095.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2800..Train loss: 0.256.. Test loss: 0.057.. Test accuracy: 0.978\n",
      "Epoch 1/1.. Step 2805..Train loss: 0.288.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 1/1.. Step 2810..Train loss: 0.097.. Test loss: 0.040.. Test accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "print_steps = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    steps = 0\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        log_ps = resmodel.forward(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_steps == 0:\n",
    "            \n",
    "            test_loss, accuracy = validator(model=resmodel, loader=testloader, batch_size=999)\n",
    "            \n",
    "#             test_loss = 0\n",
    "#             accuracy = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for images, labels in testloader:\n",
    "#                     resmodel.eval()\n",
    "                    \n",
    "#                     images, labels = images.to(device), labels.to(device)\n",
    "#                     log_ps = resmodel.forward(images)\n",
    "#                     ps = torch.exp(log_ps)\n",
    "#                     top_ps, top_pred = ps.topk(1, dim=1)\n",
    "                    \n",
    "#                     batch_loss = criterion(log_ps, labels)\n",
    "#                     test_loss += batch_loss.item()\n",
    "                    \n",
    "#                     matches = top_pred == labels.view(*top_pred.shape)\n",
    "#                     accuracy += torch.mean(matches.type(torch.float))\n",
    "                        \n",
    "            print(f\"Epoch {e+1}/{epochs}.. \"\n",
    "                  f\"Step {steps}..\"\n",
    "                  f\"Train loss: {running_loss/print_steps:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            \n",
    "            running_loss = 0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
